package scheduler

import (
	"context"
	"fmt"
	"sync"
	"time"

	"hermes/internal/ai"
	"hermes/internal/config"
	"hermes/internal/task"
	"hermes/internal/ui"
)

// Scheduler manages parallel task execution
type Scheduler struct {
	config         *config.ParallelConfig
	provider       ai.Provider
	workDir        string
	logger         *ui.Logger
	parallelLogger *ParallelLogger
	mu             sync.Mutex
}

// ExecutionPlan represents the planned execution order
type ExecutionPlan struct {
	Batches      [][]*task.Task
	TotalTasks   int
	EstimatedTime time.Duration
}

// ExecutionResult represents the result of executing all tasks
type ExecutionResult struct {
	Results     []*TaskResult
	TotalTime   time.Duration
	Successful  int
	Failed      int
	StartTime   time.Time
	EndTime     time.Time
}

// New creates a new scheduler
func New(cfg *config.ParallelConfig, provider ai.Provider, workDir string, logger *ui.Logger) *Scheduler {
	return &Scheduler{
		config:   cfg,
		provider: provider,
		workDir:  workDir,
		logger:   logger,
	}
}

// SetParallelLogger sets the parallel logger for per-worker logging
func (s *Scheduler) SetParallelLogger(logger *ParallelLogger) {
	s.parallelLogger = logger
}

// GetExecutionPlan returns the planned execution order without executing
func (s *Scheduler) GetExecutionPlan(tasks []*task.Task) (*ExecutionPlan, error) {
	graph, err := NewTaskGraph(tasks)
	if err != nil {
		return nil, fmt.Errorf("failed to build task graph: %w", err)
	}

	batches, err := graph.GetBatches()
	if err != nil {
		return nil, fmt.Errorf("failed to compute batches: %w", err)
	}

	return &ExecutionPlan{
		Batches:    batches,
		TotalTasks: len(tasks),
	}, nil
}

// Execute runs all tasks respecting dependencies
func (s *Scheduler) Execute(ctx context.Context, tasks []*task.Task) (*ExecutionResult, error) {
	startTime := time.Now()
	
	result := &ExecutionResult{
		Results:   make([]*TaskResult, 0),
		StartTime: startTime,
	}

	// Build task graph
	graph, err := NewTaskGraph(tasks)
	if err != nil {
		return nil, fmt.Errorf("failed to build task graph: %w", err)
	}

	// Get execution plan
	batches, err := graph.GetBatches()
	if err != nil {
		return nil, fmt.Errorf("failed to compute execution batches: %w", err)
	}

	s.logInfo("Execution plan: %d batches, %d total tasks", len(batches), len(tasks))
	for i, batch := range batches {
		taskIDs := make([]string, len(batch))
		for j, t := range batch {
			taskIDs[j] = t.ID
		}
		s.logInfo("  Batch %d: %v", i+1, taskIDs)
	}

	// Execute each batch
	for batchNum, batch := range batches {
		select {
		case <-ctx.Done():
			result.EndTime = time.Now()
			result.TotalTime = result.EndTime.Sub(startTime)
			return result, ctx.Err()
		default:
		}

		s.logInfo("Starting batch %d/%d with %d tasks", batchNum+1, len(batches), len(batch))

		batchResults, err := s.executeBatch(ctx, graph, batch)
		if err != nil {
			s.logError("Batch %d failed: %v", batchNum+1, err)
			
			// Handle based on failure strategy
			switch s.config.FailureStrategy {
			case "fail-fast":
				result.EndTime = time.Now()
				result.TotalTime = result.EndTime.Sub(startTime)
				result.Results = append(result.Results, batchResults...)
				s.countResults(result)
				return result, fmt.Errorf("batch %d failed: %w", batchNum+1, err)
			case "continue":
				// Continue with next batch
				result.Results = append(result.Results, batchResults...)
				continue
			}
		}

		result.Results = append(result.Results, batchResults...)
		s.logInfo("Batch %d completed", batchNum+1)
	}

	result.EndTime = time.Now()
	result.TotalTime = result.EndTime.Sub(startTime)
	s.countResults(result)

	return result, nil
}

// executeBatch executes a single batch of tasks in parallel
func (s *Scheduler) executeBatch(ctx context.Context, graph *TaskGraph, batch []*task.Task) ([]*TaskResult, error) {
	workers := s.config.MaxWorkers
	if workers > len(batch) {
		workers = len(batch)
	}

	pool := NewWorkerPoolWithConfig(ctx, s.provider, s.workDir, WorkerPoolConfig{
		Workers:      workers,
		UseIsolation: s.config.IsolatedWorkspaces,
		Logger:       s.parallelLogger,
	})
	pool.Start()

	// Mark tasks as running and submit to pool
	for _, t := range batch {
		if err := graph.MarkRunning(t.ID); err != nil {
			s.logError("Failed to mark task %s as running: %v", t.ID, err)
		}
		if err := pool.Submit(t); err != nil {
			return nil, fmt.Errorf("failed to submit task %s: %w", t.ID, err)
		}
	}

	// Collect results
	results := pool.WaitForBatch(len(batch))

	// Update graph based on results
	var batchErr error
	for _, result := range results {
		if result.Success {
			if err := graph.MarkComplete(result.TaskID); err != nil {
				s.logError("Failed to mark task %s as complete: %v", result.TaskID, err)
			}
			s.logInfo("Task %s completed successfully in %v", result.TaskID, result.Duration)
		} else {
			if err := graph.MarkFailed(result.TaskID); err != nil {
				s.logError("Failed to mark task %s as failed: %v", result.TaskID, err)
			}
			s.logError("Task %s failed: %v", result.TaskID, result.Error)
			batchErr = fmt.Errorf("task %s failed: %w", result.TaskID, result.Error)
		}
	}

	// Stop the pool
	pool.Stop()

	return results, batchErr
}

// countResults updates the result counts
func (s *Scheduler) countResults(result *ExecutionResult) {
	for _, r := range result.Results {
		if r.Success {
			result.Successful++
		} else {
			result.Failed++
		}
	}
}

func (s *Scheduler) logInfo(format string, args ...interface{}) {
	if s.logger != nil {
		s.logger.Info(format, args...)
	}
}

func (s *Scheduler) logError(format string, args ...interface{}) {
	if s.logger != nil {
		s.logger.Error(format, args...)
	}
}

// PrintExecutionPlan prints the execution plan in a user-friendly format
func (s *Scheduler) PrintExecutionPlan(plan *ExecutionPlan) {
	fmt.Println("\nðŸ“‹ Execution Plan")
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Printf("Total Tasks: %d\n", plan.TotalTasks)
	fmt.Printf("Batches: %d\n", len(plan.Batches))
	fmt.Printf("Max Workers: %d\n\n", s.config.MaxWorkers)

	for i, batch := range plan.Batches {
		fmt.Printf("Batch %d (%d tasks):\n", i+1, len(batch))
		for _, t := range batch {
			parallel := "âœ“"
			if !t.Parallelizable {
				parallel = "âœ—"
			}
			fmt.Printf("  [%s] %s - %s (parallel: %s)\n", t.ID, t.Name, t.Priority, parallel)
			if len(t.DependsOn) > 0 {
				fmt.Printf("       â””â”€ depends on: %v\n", t.DependsOn)
			}
		}
		if i < len(plan.Batches)-1 {
			fmt.Println("  â†“")
		}
	}
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
}

// PrintExecutionResult prints the execution result summary
func (s *Scheduler) PrintExecutionResult(result *ExecutionResult) {
	fmt.Println("\nðŸ“Š Execution Result")
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Printf("Total Time: %v\n", result.TotalTime.Round(time.Second))
	fmt.Printf("Successful: %d\n", result.Successful)
	fmt.Printf("Failed: %d\n", result.Failed)
	fmt.Println()

	for _, r := range result.Results {
		status := "âœ“"
		if !r.Success {
			status = "âœ—"
		}
		fmt.Printf("[%s] %s - %s (%v)\n", status, r.TaskID, r.TaskName, r.Duration.Round(time.Second))
		if r.Error != nil {
			fmt.Printf("     Error: %v\n", r.Error)
		}
	}
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
}
